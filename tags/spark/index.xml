<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on 大王派我来搬砖</title>
    <link>http://gopherday.com/tags/spark/</link>
    <description>Recent content in Spark on 大王派我来搬砖</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>tx991020@gmail.com (andy wu)</managingEditor>
    <webMaster>tx991020@gmail.com (andy wu)</webMaster>
    <lastBuildDate>Sun, 12 Feb 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://gopherday.com/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>spark sql优化原理图</title>
      <link>http://gopherday.com/post/2017-02-12-spark-pic/</link>
      <pubDate>Sun, 12 Feb 2017 00:00:00 +0000</pubDate>
      <author>tx991020@gmail.com (andy wu)</author>
      <guid>http://gopherday.com/post/2017-02-12-spark-pic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>spark streaming</title>
      <link>http://gopherday.com/post/2017-02-11-sparkstreaming/</link>
      <pubDate>Sat, 11 Feb 2017 00:00:00 +0000</pubDate>
      <author>tx991020@gmail.com (andy wu)</author>
      <guid>http://gopherday.com/post/2017-02-11-sparkstreaming/</guid>
      <description>from pyspark.sql import SparkSession from pyspark.streaming.kafka import KafkaUtils from pyspark.streaming import StreamingContext if __name__ == &amp;#39;__main__&amp;#39;: topic =&amp;#34;test&amp;#34; spark = SparkSession.builder.appName(&amp;#34;Python Spark &amp;#34;).master(&amp;#34;local[2]&amp;#34;).getOrCreate() sc = spark.sparkContext ssc = StreamingContext(sc, 10) kvs = KafkaUtils.createDirectStream(ssc,[topic],{&amp;#34;metadata.broker.list&amp;#34;:&amp;#34;127.0.0.1:9092&amp;#34;}) lines = kvs.map(lambda x: x[1]) counts = lines.flatMap(lambda line: line.split(&amp;#34; &amp;#34;)) \ .map(lambda word: (word, 1)) \ .reduceByKey(lambda a, b: a + b) counts.pprint() ssc.start() ssc.awaitTermination() </description>
    </item>
    
    <item>
      <title>sparksql</title>
      <link>http://gopherday.com/post/2017-02-10-sparksql/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <author>tx991020@gmail.com (andy wu)</author>
      <guid>http://gopherday.com/post/2017-02-10-sparksql/</guid>
      <description>from pyspark.sql import SparkSession if __name__ == &amp;#39;__main__&amp;#39;: spark = SparkSession.builder.appName(&amp;#34;Python Spark &amp;#34;).master(&amp;#34;local[2]&amp;#34;).getOrCreate() jdbcDF = spark.read.format(&amp;#34;jdbc&amp;#34;).option(&amp;#34;url&amp;#34;, &amp;#34;jdbc:mysql://localhost:3306/video&amp;#34;).option(&amp;#34;driver&amp;#34;,&amp;#34;com.mysql.jdbc.Driver&amp;#34;).option(&amp;#34;dbtable&amp;#34;, &amp;#34;baidu&amp;#34;).option(&amp;#34;user&amp;#34;, &amp;#34;root&amp;#34;).option(&amp;#34;password&amp;#34;, &amp;#34;123456&amp;#34;).load() jdbcDF.show() </description>
    </item>
    
  </channel>
</rss>